# Scope and Sequence

Subject to change. 

## Week 1: Math & Programming Fundamentals
  - Python & NumPy: Demonstrate introductory programming concepts using Python and NumPy as a tool to navigate data sources and collections
  - Unix: Utilize UNIX commands to navigate file systems and modify files 
  - git: Maintain a git repository in order to keep track of changes and iterations as your project evolves.
  - Descriptive Statistics: Define and apply descriptive statistic fundamentals
  - Intro to plotting and visualization: Practice using plot.ly, iPython notebook and Tableau to plot and visualize data
  - Project 1: Provided with a dataset of SAT scores from across the United States, students will perform exploratory analysis using NumPy, Matplotlib and Tableau to apply basic summary statistics. 


## Week 2: EDA, Pandas & SciPy
  - Experiment Design: Plan experimental study design with a well thought out problem statement and data framework
  - Pandas & Pivot Tables: Use Pandas to read, clean, parse and plot data using functions such as boolean, indexing, math series, joins and others
  - SciPy: Review statistical testing concepts(p-values, confidence intervals, lamba functions, correlation/causation) with SciPy
  - Project 2: Using a dirty dataset of Billboard hits, students will use Pandas to munge data, create a problem statement and perform exploratory analysis for a local music publisher. 


## Week 3: Linear Regressions, SciKit-Learn, Gradient Descent Regularization & Model Fit
  - Linear regression, stats models and scikit learn: Use scikit learn ans statsmodels to run linear regression models and evaluate model
  - Bias-Variance Tradeoff: Understand bias-variance trade-off to evaluate machine learning models
  - Gradient Descent: Look behind the hood at the math and theory of how gradient descent helps to optimize the loss functions for models
  - Regularization & Optimization: Learn to apply regularization and optimization when evaluating model fit
  - Project 3: Given access to state liquor sales data, students will choose between performing market research or conducting tax audits, using Pandas, stats models, and sklearn to transform data, perform linear regression and plot results. 


## Week 4: Linear Regressions, SciKit-Learn, Gradient Descent Regularization & Model Fit
  - Web Scraping: Learn to scrape website data using scraping tools
  - Logistic Regression: Build, evaluate and refine a logistic regression model for a given business case study
  - NLP: Get introduced to natural language processing through sentiment analysis of scraped website data
  - Intro to Capstone Project: Get introduced to the final project. Begin to plan your experiment design and look for data sources. 
  - Project 4: Posing as a federal contractor, students will scrape website data and use Pandas, Statsmodels and NLTK to clean and analyze data, perform logistic regression and evaluate correlation coefficients. 

## Week 5: SQL, Databases & Classification
  - SQL & Remote Databases
  - Get introduced to different types of databases, review SQL commands and practice connecting to and pulling data from a remote AWS database
  - Feature Selection: Use feature selection to deepen knowledge of model evaluation
  - kNN & SVMs: Begin to look at classification models through an application of the kNN algorithm and learn how SVMs can simplify the process of analyzing data for supervised learning algorithms. 
  - Project 5: As a researcher for a disaster response agency, students will pull remote data on Titanic survivors in order to build a local database, run a logistic regression classification model and validate results from test subsets. 


## Week 6: APIs, Trees & Ensemble Methods
  - JSON & APIs: Learn to pull JSON data from APIs as another potential data source
  - Ensemble Models: Build and evaluate ensemble models using decision trees, random forests, bagging and boosting
  - Project 6: Acting as a member of the Netflix data science team, students will collect data from IMDB's API and use SQL in order to construct a random forest model that identifies ratings indicators and correlates these findings with viewer sentiment analysis. 


## Week 7: PCA, Clustering, K-Means & AWS
  - Clustering: Define clustering and its advantages and disadvantages from classification models
  - K-Means: Practice building and evaluating a k-means algorithm
  - PCA: Convert a set of observations or variables into principal components in order to improve predictive analysis
  - PostgreSQL: Learn to build and maintain your own postgreSQL database
  - Project 7: Working as an airport operations consultant, students will analyze plane delay data in US airports performing a principle component analysis


## Week 8: Bayesian Inference & LDA
  - Bayesian Methods: Build a linear regression model with bayesian methods
  - LDA: Refine data using latent dirichlet allocation (LDA)
  - Naive Bayes: Learn how Naive Bayes can simplify the process of analyzing data for supervised learning algorithms
  - Capstone Project, Part 1: During the first part of the capstone project, students will select and verify topics and datasets, in order to develop problem statements, goals and success criteria. 


## Week 9: Working with Times Series
  - Time Series & Autocorrelation: Analyze and visualize time series data using Pandas, plot.ly and Tableau.
  - ARIMA Model: Use the ARIMA model to make predictions with time series data
  - Capstone Project, Part 2: During the second part of the capstone project, students will create their own database, acquire and clean their data and perform exploratory data analysis using real world tools and processes. 

## Week 10: Intro to Big Data & Spark
  - Hadoop & MapReduce: Get introduced to the history and use fo Hadoop as well as the advantages and disadvantages of using parallel or distributed systems to store, access and analyze big data
  - Hive & Spark: Gain an introductory understanding of how Hive interacts with Hadoop and learn about Spark's advantages through big data case studies
  - Capstone Project, Part 3: During the third part of the capstone project, students will build and tune a predictive model from their data using machine learning algorithms to analyze, classify and plot their data
  

## Week 11-12: Job Prep & Capstone
  - Portfolio Development: Work with career coaches to create and polish your portfolio for employers
  - Interview Prep: Practice data science case studies to prep for job interviews
  - Advanced Topics TBD
  - Capstone Project, Part 4 and 5: Students will create a detailed technical model notebook to share with peer audiences while adapting their findings into a visual narrative for non-technical stakeholders


  


  
